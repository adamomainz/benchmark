{
    "name": "group_bench",
    "environ": {
        "pytorch_git_version": "2ed1b1747a0afa73310846c1172489e9467bec91",
        "pytorch_version": "2.3.0a0+git2ed1b17",
        "device": "NVIDIA PG509-210"
    },
    "metrics": {
        "model=BERT_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=BERT_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=Background_Matting, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "not_implemented",
        "model=Background_Matting, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "not_implemented",
        "model=DALLE2_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=DALLE2_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=LearningToPaint, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=LearningToPaint, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=Super_SloMo, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 27.74275,
        "model=Super_SloMo, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 28.92413330078125,
        "model=alexnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 2.904752,
        "model=alexnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.69757080078125,
        "model=basic_gnn_edgecnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.942141,
        "model=basic_gnn_edgecnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.15460205078125,
        "model=basic_gnn_gcn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 3.990571,
        "model=basic_gnn_gcn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.07647705078125,
        "model=basic_gnn_gin, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.577611,
        "model=basic_gnn_gin, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.07452392578125,
        "model=basic_gnn_sage, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 3.406897,
        "model=basic_gnn_sage, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.07647705078125,
        "model=cm3leon_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=cm3leon_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=dcgan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.702953,
        "model=dcgan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.49639892578125,
        "model=demucs, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 45.55803,
        "model=demucs, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 29.17803955078125,
        "model=densenet121, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 10.191682,
        "model=densenet121, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.88507080078125,
        "model=detectron2_fasterrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_101_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_101_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_50_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_50_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=detectron2_fcos_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 18.064843,
        "model=detectron2_fcos_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 27.18975830078125,
        "model=detectron2_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=detectron2_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=dlrm, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.898129,
        "model=dlrm, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 27.21124267578125,
        "model=doctr_det_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=doctr_det_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=doctr_reco_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 6.343428,
        "model=doctr_reco_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.14483642578125,
        "model=drq, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=drq, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=fastNLP_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=fastNLP_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=functorch_dp_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.103178,
        "model=functorch_dp_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.09014892578125,
        "model=functorch_maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 0.440496,
        "model=functorch_maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.04327392578125,
        "model=hf_Albert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 4.149081,
        "model=hf_Albert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.07647705078125,
        "model=hf_Bart, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 5.866194,
        "model=hf_Bart, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.51983642578125,
        "model=hf_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 4.933516,
        "model=hf_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.41436767578125,
        "model=hf_Bert_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 8.355746,
        "model=hf_Bert_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.70928955078125,
        "model=hf_BigBird, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 17.149939,
        "model=hf_BigBird, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 27.04718017578125,
        "model=hf_DistilBert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.507775,
        "model=hf_DistilBert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.34210205078125,
        "model=hf_GPT2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 3.948924,
        "model=hf_GPT2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.69171142578125,
        "model=hf_GPT2_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 19.028335,
        "model=hf_GPT2_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 28.27569580078125,
        "model=hf_Longformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 21.935124,
        "model=hf_Longformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 27.31671142578125,
        "model=hf_Reformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 2.770269,
        "model=hf_Reformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.13702392578125,
        "model=hf_T5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 11.698392,
        "model=hf_T5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.89483642578125,
        "model=hf_T5_base, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 33.022634,
        "model=hf_T5_base, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 27.58624267578125,
        "model=hf_T5_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 541.645745,
        "model=hf_T5_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 29.06280517578125,
        "model=hf_T5_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 13.727596,
        "model=hf_T5_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 28.10772705078125,
        "model=hf_Whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 0.477408,
        "model=hf_Whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.03350830078125,
        "model=hf_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 7.007441,
        "model=hf_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 27.46124267578125,
        "model=hf_distil_whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.283584,
        "model=hf_distil_whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.62139892578125,
        "model=lennard_jones, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=lennard_jones, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=llama, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 7.391013,
        "model=llama, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 28.19757080078125,
        "model=llama_v2_7b_16h, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 23.971207,
        "model=llama_v2_7b_16h, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 33.04522705078125,
        "model=llava, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.293592,
        "model=llava, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 39.55303955078125,
        "model=maml, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "not_implemented",
        "model=maml, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "not_implemented",
        "model=maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 0.481232,
        "model=maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.04327392578125,
        "model=mnasnet1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 2.097818,
        "model=mnasnet1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.38116455078125,
        "model=mobilenet_v2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.520891,
        "model=mobilenet_v2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.39874267578125,
        "model=mobilenet_v2_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "not_implemented",
        "model=mobilenet_v2_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "not_implemented",
        "model=mobilenet_v3_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 2.006205,
        "model=mobilenet_v3_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.48272705078125,
        "model=moco, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=moco, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=moondream, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 0.390151,
        "model=moondream, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 28.83624267578125,
        "model=nanogpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 116.371412,
        "model=nanogpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.41046142578125,
        "model=nvidia_deeprecommender, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=nvidia_deeprecommender, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=opacus_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.277513,
        "model=opacus_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.10968017578125,
        "model=phlippe_densenet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 2.453632,
        "model=phlippe_densenet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.19171142578125,
        "model=phlippe_resnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "Exceeded timeout: 3600",
        "model=phlippe_resnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=pyhpc_equation_of_state, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 0.528286,
        "model=pyhpc_equation_of_state, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.07061767578125,
        "model=pyhpc_isoneutral_mixing, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 4.58573,
        "model=pyhpc_isoneutral_mixing, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.95733642578125,
        "model=pyhpc_turbulent_kinetic_energy, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 2.337185,
        "model=pyhpc_turbulent_kinetic_energy, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.50225830078125,
        "model=pytorch_CycleGAN_and_pix2pix, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "Exceeded timeout: 3600",
        "model=pytorch_CycleGAN_and_pix2pix, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=pytorch_stargan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 4.678501,
        "model=pytorch_stargan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.94561767578125,
        "model=pytorch_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 9.266223,
        "model=pytorch_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.56866455078125,
        "model=resnet152, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 9.529788,
        "model=resnet152, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.66046142578125,
        "model=resnet18, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.063995,
        "model=resnet18, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.18585205078125,
        "model=resnet50, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 4.419304,
        "model=resnet50, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.55499267578125,
        "model=resnet50_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "not_implemented",
        "model=resnet50_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "not_implemented",
        "model=resnext50_32x4d, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 2.132303,
        "model=resnext50_32x4d, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.22100830078125,
        "model=sam, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=sam, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=sam_fast, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "[Errno 2] No such file or directory",
        "model=sam_fast, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "[Errno 2] No such file or directory",
        "model=shufflenet_v2_x1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 2.351571,
        "model=shufflenet_v2_x1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.64874267578125,
        "model=simple_gpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "not_implemented",
        "model=simple_gpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "not_implemented",
        "model=simple_gpt_tp_manual, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "not_implemented",
        "model=simple_gpt_tp_manual, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "not_implemented",
        "model=soft_actor_critic, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=soft_actor_critic, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=speech_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=speech_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=squeezenet1_1, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 0.894866,
        "model=squeezenet1_1, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.21710205078125,
        "model=stable_diffusion_text_encoder, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=stable_diffusion_text_encoder, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=stable_diffusion_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=stable_diffusion_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=tacotron2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=tacotron2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=timm_efficientdet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "Exceeded timeout: 3600",
        "model=timm_efficientdet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=timm_efficientnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 5.495338,
        "model=timm_efficientnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 27.41241455078125,
        "model=timm_nfnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 24.604778,
        "model=timm_nfnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 27.84014892578125,
        "model=timm_regnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 13.001771,
        "model=timm_regnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 27.04132080078125,
        "model=timm_resnest, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 6.908365,
        "model=timm_resnest, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 28.42608642578125,
        "model=timm_vision_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 4.235004,
        "model=timm_vision_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.36749267578125,
        "model=timm_vision_transformer_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 113.245878,
        "model=timm_vision_transformer_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 28.93975830078125,
        "model=timm_vovnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 4.831711,
        "model=timm_vovnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.50616455078125,
        "model=torch_multimodal_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=torch_multimodal_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=tts_angular, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "err",
        "model=tts_angular, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "err",
        "model=vgg16, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 1.567038,
        "model=vgg16, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 26.86749267578125,
        "model=vision_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": "Exceeded timeout: 3600",
        "model=vision_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=yolov3, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=latencies": 29.182423,
        "model=yolov3, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune, metric=gpu_peak_mem": 28.46905517578125,
        "model=BERT_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "Exceeded timeout: 3600",
        "model=BERT_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=Background_Matting, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "not_implemented",
        "model=Background_Matting, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "not_implemented",
        "model=DALLE2_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=DALLE2_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=LearningToPaint, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "Exceeded timeout: 3600",
        "model=LearningToPaint, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=Super_SloMo, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 28.071531,
        "model=Super_SloMo, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 28.92608642578125,
        "model=alexnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 2.971723,
        "model=alexnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.66436767578125,
        "model=basic_gnn_edgecnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.956899,
        "model=basic_gnn_edgecnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.17022705078125,
        "model=basic_gnn_gcn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 4.445667,
        "model=basic_gnn_gcn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.09210205078125,
        "model=basic_gnn_gin, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.566521,
        "model=basic_gnn_gin, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.09014892578125,
        "model=basic_gnn_sage, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 3.075412,
        "model=basic_gnn_sage, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.09210205078125,
        "model=cm3leon_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 245.633438,
        "model=cm3leon_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 29.04132080078125,
        "model=dcgan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.71037,
        "model=dcgan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.49639892578125,
        "model=demucs, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 45.860832,
        "model=demucs, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 28.82843017578125,
        "model=densenet121, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 10.595126,
        "model=densenet121, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.86749267578125,
        "model=detectron2_fasterrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_101_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_101_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_50_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_50_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=detectron2_fcos_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 18.154425,
        "model=detectron2_fcos_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 27.43194580078125,
        "model=detectron2_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=detectron2_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=dlrm, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.918756,
        "model=dlrm, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 27.21319580078125,
        "model=doctr_det_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=doctr_det_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=doctr_reco_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 6.568216,
        "model=doctr_reco_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.14678955078125,
        "model=drq, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=drq, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=fastNLP_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=fastNLP_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=functorch_dp_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.104021,
        "model=functorch_dp_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.10577392578125,
        "model=functorch_maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 0.436586,
        "model=functorch_maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.05889892578125,
        "model=hf_Albert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 4.381573,
        "model=hf_Albert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.09991455078125,
        "model=hf_Bart, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 11.504612,
        "model=hf_Bart, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.54327392578125,
        "model=hf_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 6.272107,
        "model=hf_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.67999267578125,
        "model=hf_Bert_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 9.226098,
        "model=hf_Bert_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.76202392578125,
        "model=hf_BigBird, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 17.225274,
        "model=hf_BigBird, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 27.90069580078125,
        "model=hf_DistilBert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.518281,
        "model=hf_DistilBert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.34405517578125,
        "model=hf_GPT2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 4.125428,
        "model=hf_GPT2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.97100830078125,
        "model=hf_GPT2_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 19.886176,
        "model=hf_GPT2_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 28.33624267578125,
        "model=hf_Longformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 23.407458,
        "model=hf_Longformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 28.02569580078125,
        "model=hf_Reformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 2.755911,
        "model=hf_Reformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.13897705078125,
        "model=hf_T5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 12.133772,
        "model=hf_T5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.90460205078125,
        "model=hf_T5_base, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 34.150792,
        "model=hf_T5_base, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 27.60968017578125,
        "model=hf_T5_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 669.164093,
        "model=hf_T5_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 28.93975830078125,
        "model=hf_T5_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 14.270317,
        "model=hf_T5_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 28.18194580078125,
        "model=hf_Whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 0.602611,
        "model=hf_Whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.08233642578125,
        "model=hf_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=hf_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=hf_distil_whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.998766,
        "model=hf_distil_whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.74053955078125,
        "model=lennard_jones, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=lennard_jones, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=llama, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 7.013754,
        "model=llama, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.97686767578125,
        "model=llama_v2_7b_16h, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 18.883716,
        "model=llama_v2_7b_16h, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 36.30108642578125,
        "model=llava, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 2.884513,
        "model=llava, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 46.19171142578125,
        "model=maml, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "not_implemented",
        "model=maml, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "not_implemented",
        "model=maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 0.451951,
        "model=maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.05694580078125,
        "model=mnasnet1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 2.084983,
        "model=mnasnet1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.38507080078125,
        "model=mobilenet_v2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.491123,
        "model=mobilenet_v2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.40264892578125,
        "model=mobilenet_v2_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "not_implemented",
        "model=mobilenet_v2_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "not_implemented",
        "model=mobilenet_v3_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.973783,
        "model=mobilenet_v3_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.48663330078125,
        "model=moco, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=moco, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=moondream, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 0.95683,
        "model=moondream, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 29.67608642578125,
        "model=nanogpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 118.894759,
        "model=nanogpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.67413330078125,
        "model=nvidia_deeprecommender, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=nvidia_deeprecommender, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=opacus_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.243579,
        "model=opacus_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.12530517578125,
        "model=phlippe_densenet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 2.384016,
        "model=phlippe_densenet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.20733642578125,
        "model=phlippe_resnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "Exceeded timeout: 3600",
        "model=phlippe_resnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=pyhpc_equation_of_state, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 0.514587,
        "model=pyhpc_equation_of_state, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.07061767578125,
        "model=pyhpc_isoneutral_mixing, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 4.511957,
        "model=pyhpc_isoneutral_mixing, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.95733642578125,
        "model=pyhpc_turbulent_kinetic_energy, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 2.289205,
        "model=pyhpc_turbulent_kinetic_energy, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 2.29913330078125,
        "model=pytorch_CycleGAN_and_pix2pix, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "Exceeded timeout: 3600",
        "model=pytorch_CycleGAN_and_pix2pix, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=pytorch_stargan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 4.616512,
        "model=pytorch_stargan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.79913330078125,
        "model=pytorch_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 9.220401,
        "model=pytorch_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.59991455078125,
        "model=resnet152, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 9.378057,
        "model=resnet152, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.68585205078125,
        "model=resnet18, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.060035,
        "model=resnet18, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.22491455078125,
        "model=resnet50, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 4.391579,
        "model=resnet50, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.58038330078125,
        "model=resnet50_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "not_implemented",
        "model=resnet50_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "not_implemented",
        "model=resnext50_32x4d, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 2.112957,
        "model=resnext50_32x4d, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.24639892578125,
        "model=sam, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "Exceeded timeout: 3600",
        "model=sam, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=sam_fast, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "[Errno 2] No such file or directory",
        "model=sam_fast, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "[Errno 2] No such file or directory",
        "model=shufflenet_v2_x1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 2.32422,
        "model=shufflenet_v2_x1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.67413330078125,
        "model=simple_gpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "not_implemented",
        "model=simple_gpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "not_implemented",
        "model=simple_gpt_tp_manual, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "not_implemented",
        "model=simple_gpt_tp_manual, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "not_implemented",
        "model=soft_actor_critic, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "Exceeded timeout: 3600",
        "model=soft_actor_critic, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=speech_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=speech_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=squeezenet1_1, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 0.868888,
        "model=squeezenet1_1, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.24053955078125,
        "model=stable_diffusion_text_encoder, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=stable_diffusion_text_encoder, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=stable_diffusion_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=stable_diffusion_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=tacotron2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=tacotron2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=timm_efficientdet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "Exceeded timeout: 3600",
        "model=timm_efficientdet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=timm_efficientnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 5.442461,
        "model=timm_efficientnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 27.43975830078125,
        "model=timm_nfnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 24.515045,
        "model=timm_nfnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 27.28936767578125,
        "model=timm_regnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 12.92524,
        "model=timm_regnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.95538330078125,
        "model=timm_resnest, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 6.914411,
        "model=timm_resnest, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 28.06866455078125,
        "model=timm_vision_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 4.204393,
        "model=timm_vision_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.41241455078125,
        "model=timm_vision_transformer_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 108.831744,
        "model=timm_vision_transformer_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 29.82647705078125,
        "model=timm_vovnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 4.828616,
        "model=timm_vovnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 26.53155517578125,
        "model=torch_multimodal_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=torch_multimodal_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=tts_angular, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "err",
        "model=tts_angular, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "err",
        "model=vgg16, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 1.605805,
        "model=vgg16, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 27.03546142578125,
        "model=vision_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": "Exceeded timeout: 3600",
        "model=vision_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=yolov3, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=latencies": 9.571046,
        "model=yolov3, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization autoquant, metric=gpu_peak_mem": 28.20928955078125,
        "model=BERT_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=BERT_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=Background_Matting, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "not_implemented",
        "model=Background_Matting, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "not_implemented",
        "model=DALLE2_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "Exceeded timeout: 3600",
        "model=DALLE2_pytorch, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=LearningToPaint, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "Exceeded timeout: 3600",
        "model=LearningToPaint, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=Super_SloMo, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 28.018809,
        "model=Super_SloMo, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 28.94757080078125,
        "model=alexnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 3.070908,
        "model=alexnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.65069580078125,
        "model=basic_gnn_edgecnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 1.958695,
        "model=basic_gnn_edgecnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.17803955078125,
        "model=basic_gnn_gcn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 3.954779,
        "model=basic_gnn_gcn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.09991455078125,
        "model=basic_gnn_gin, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 1.544443,
        "model=basic_gnn_gin, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.09796142578125,
        "model=basic_gnn_sage, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 3.362008,
        "model=basic_gnn_sage, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.09991455078125,
        "model=cm3leon_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=cm3leon_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=dcgan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 1.751707,
        "model=dcgan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.51983642578125,
        "model=demucs, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 45.668452,
        "model=demucs, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 29.19366455078125,
        "model=densenet121, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 10.701671,
        "model=densenet121, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.88897705078125,
        "model=detectron2_fasterrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_101_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_101_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_50_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_50_dc5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=detectron2_fasterrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=detectron2_fasterrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=detectron2_fcos_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 20.093337,
        "model=detectron2_fcos_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 27.21319580078125,
        "model=detectron2_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=detectron2_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_101_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_101_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_50_c4, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=detectron2_maskrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=detectron2_maskrcnn_r_50_fpn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=dlrm, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 2.739702,
        "model=dlrm, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 27.23858642578125,
        "model=doctr_det_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=doctr_det_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=doctr_reco_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 6.520179,
        "model=doctr_reco_predictor, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.16827392578125,
        "model=drq, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=drq, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=fastNLP_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=fastNLP_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=functorch_dp_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 1.178059,
        "model=functorch_dp_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.11358642578125,
        "model=functorch_maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 0.48478,
        "model=functorch_maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.06671142578125,
        "model=hf_Albert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 3.832248,
        "model=hf_Albert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.08624267578125,
        "model=hf_Bart, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 6.606263,
        "model=hf_Bart, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.89678955078125,
        "model=hf_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 4.480494,
        "model=hf_Bert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.47686767578125,
        "model=hf_Bert_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 15.522346,
        "model=hf_Bert_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.96124267578125,
        "model=hf_BigBird, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 17.237372,
        "model=hf_BigBird, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 27.50225830078125,
        "model=hf_DistilBert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 2.022534,
        "model=hf_DistilBert, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.56280517578125,
        "model=hf_GPT2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 4.274393,
        "model=hf_GPT2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.75421142578125,
        "model=hf_GPT2_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 19.317016,
        "model=hf_GPT2_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 28.35968017578125,
        "model=hf_Longformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 25.715455,
        "model=hf_Longformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 27.87139892578125,
        "model=hf_Reformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 3.331604,
        "model=hf_Reformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.37725830078125,
        "model=hf_T5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 12.658922,
        "model=hf_T5, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.97100830078125,
        "model=hf_T5_base, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 36.616954,
        "model=hf_T5_base, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 27.68780517578125,
        "model=hf_T5_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 711.364829,
        "model=hf_T5_generate, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 29.48858642578125,
        "model=hf_T5_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 18.20391,
        "model=hf_T5_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 28.96905517578125,
        "model=hf_Whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 0.683761,
        "model=hf_Whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.06085205078125,
        "model=hf_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 11.35538,
        "model=hf_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 27.91241455078125,
        "model=hf_distil_whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 2.325525,
        "model=hf_distil_whisper, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.95928955078125,
        "model=lennard_jones, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=lennard_jones, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=llama, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 6.500161,
        "model=llama, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 28.13311767578125,
        "model=llama_v2_7b_16h, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 18.936292,
        "model=llama_v2_7b_16h, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 36.73468017578125,
        "model=llava, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 3.020687,
        "model=llava, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 46.74639892578125,
        "model=maml, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "not_implemented",
        "model=maml, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "not_implemented",
        "model=maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 0.624652,
        "model=maml_omniglot, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.06671142578125,
        "model=mnasnet1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 2.298369,
        "model=mnasnet1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.42413330078125,
        "model=mobilenet_v2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 1.691105,
        "model=mobilenet_v2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.66241455078125,
        "model=mobilenet_v2_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "not_implemented",
        "model=mobilenet_v2_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "not_implemented",
        "model=mobilenet_v3_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 2.172505,
        "model=mobilenet_v3_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.50616455078125,
        "model=moco, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=moco, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=moondream, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 1.502032,
        "model=moondream, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 30.04718017578125,
        "model=nanogpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 99.883117,
        "model=nanogpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.67022705078125,
        "model=nvidia_deeprecommender, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=nvidia_deeprecommender, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=opacus_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 1.314089,
        "model=opacus_cifar10, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.13311767578125,
        "model=phlippe_densenet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 2.58426,
        "model=phlippe_densenet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.45538330078125,
        "model=phlippe_resnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "Exceeded timeout: 3600",
        "model=phlippe_resnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=pyhpc_equation_of_state, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 0.503361,
        "model=pyhpc_equation_of_state, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.09405517578125,
        "model=pyhpc_isoneutral_mixing, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 4.485621,
        "model=pyhpc_isoneutral_mixing, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.98077392578125,
        "model=pyhpc_turbulent_kinetic_energy, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 2.289519,
        "model=pyhpc_turbulent_kinetic_energy, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.52569580078125,
        "model=pytorch_CycleGAN_and_pix2pix, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "Exceeded timeout: 3600",
        "model=pytorch_CycleGAN_and_pix2pix, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=pytorch_stargan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 4.605829,
        "model=pytorch_stargan, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.96905517578125,
        "model=pytorch_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 9.244325,
        "model=pytorch_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.59210205078125,
        "model=resnet152, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 9.885032,
        "model=resnet152, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.68389892578125,
        "model=resnet18, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 1.138066,
        "model=resnet18, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.21124267578125,
        "model=resnet50, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 4.575485,
        "model=resnet50, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.57843017578125,
        "model=resnet50_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "not_implemented",
        "model=resnet50_quantized_qat, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "not_implemented",
        "model=resnext50_32x4d, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 2.283378,
        "model=resnext50_32x4d, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.48663330078125,
        "model=sam, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=sam, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=sam_fast, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "[Errno 2] No such file or directory",
        "model=sam_fast, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "[Errno 2] No such file or directory",
        "model=shufflenet_v2_x1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 2.504082,
        "model=shufflenet_v2_x1_0, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.65264892578125,
        "model=simple_gpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "not_implemented",
        "model=simple_gpt, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "not_implemented",
        "model=simple_gpt_tp_manual, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "not_implemented",
        "model=simple_gpt_tp_manual, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "not_implemented",
        "model=soft_actor_critic, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "Exceeded timeout: 3600",
        "model=soft_actor_critic, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=speech_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=speech_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=squeezenet1_1, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 0.863066,
        "model=squeezenet1_1, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.24053955078125,
        "model=stable_diffusion_text_encoder, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=stable_diffusion_text_encoder, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=stable_diffusion_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=stable_diffusion_unet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=tacotron2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=tacotron2, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=timm_efficientdet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "Exceeded timeout: 3600",
        "model=timm_efficientdet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=timm_efficientnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 5.697695,
        "model=timm_efficientnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 27.43585205078125,
        "model=timm_nfnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 24.817898,
        "model=timm_nfnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 27.85577392578125,
        "model=timm_regnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 13.177577,
        "model=timm_regnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 27.05694580078125,
        "model=timm_resnest, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 6.996477,
        "model=timm_resnest, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 28.44171142578125,
        "model=timm_vision_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 6.189943,
        "model=timm_vision_transformer, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.63897705078125,
        "model=timm_vision_transformer_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 108.615058,
        "model=timm_vision_transformer_large, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 29.75616455078125,
        "model=timm_vovnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 4.992802,
        "model=timm_vovnet, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.53155517578125,
        "model=torch_multimodal_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=torch_multimodal_clip, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=tts_angular, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "err",
        "model=tts_angular, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "err",
        "model=vgg16, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 1.634094,
        "model=vgg16, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 26.71905517578125,
        "model=vision_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": "Exceeded timeout: 3600",
        "model=vision_maskrcnn, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": "Exceeded timeout: 3600",
        "model=yolov3, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=latencies": 22.690467,
        "model=yolov3, test=eval, device=cuda, bs=None, extra_args=--precision bf16 --torchdynamo inductor --inductor-compile-mode max-autotune --quantization int8dynamic, metric=gpu_peak_mem": 28.52178955078125
    }
}